{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cIU8AwSGz24P",
    "outputId": "9521a560-ec05-478b-9dc6-0c303d45b921"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: preprocessing in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (0.1.13)\n",
      "Requirement already satisfied: nltk==3.2.4 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from preprocessing) (3.2.4)\n",
      "Requirement already satisfied: sphinx-rtd-theme==0.2.4 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from preprocessing) (0.2.4)\n",
      "Requirement already satisfied: six in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from nltk==3.2.4->preprocessing) (1.16.0)\n",
      "Requirement already satisfied: connected-components-3d in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (3.12.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from connected-components-3d) (1.26.4)\n",
      "Requirement already satisfied: tables in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from tables) (1.26.4)\n",
      "Requirement already satisfied: numexpr>=2.6.2 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from tables) (2.9.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from tables) (23.2)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from tables) (9.0.0)\n",
      "Requirement already satisfied: blosc2>=2.3.0 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from tables) (2.5.1)\n",
      "Requirement already satisfied: ndindex>=1.4 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from blosc2>=2.3.0->tables) (1.8)\n",
      "Requirement already satisfied: msgpack in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from blosc2>=2.3.0->tables) (1.0.8)\n",
      "Requirement already satisfied: music21 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (9.1.0)\n",
      "Requirement already satisfied: chardet in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from music21) (5.2.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from music21) (1.3.2)\n",
      "Requirement already satisfied: jsonpickle in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from music21) (3.0.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from music21) (3.8.3)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from music21) (10.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from music21) (1.26.4)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from music21) (2.31.0)\n",
      "Requirement already satisfied: webcolors>=1.5 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from music21) (1.13)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from matplotlib->music21) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from matplotlib->music21) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from matplotlib->music21) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from matplotlib->music21) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from matplotlib->music21) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from matplotlib->music21) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from matplotlib->music21) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from matplotlib->music21) (2.9.0.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from requests->music21) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from requests->music21) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from requests->music21) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from requests->music21) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\.virtualenvs\\diplomna\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->music21) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install preprocessing\n",
    "!pip install connected-components-3d\n",
    "!pip install tables\n",
    "!pip install music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JcBdifymzr6Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\.virtualenvs\\Diplomna\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import pickle\n",
    "import os\n",
    "import zipfile\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "from skimage.color import rgb2gray\n",
    "from preprocessing import *\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from skimage.morphology import thin\n",
    "from skimage.color import label2rgb\n",
    "from collections import Counter\n",
    "\n",
    "#NN\n",
    "from sklearn import preprocessing\n",
    "from skimage.filters import threshold_otsu, gaussian, median\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from skimage.morphology import binary_opening, binary_closing, binary_dilation, binary_erosion, closing, opening, square, skeletonize, disk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.measure import label, regionprops\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, InputLayer, Dropout\n",
    "\n",
    "# web scraping imports\n",
    "from bs4 import BeautifulSoup\n",
    "# audio file\n",
    "from scipy.io.wavfile import write\n",
    "from music21 import note, stream, tempo, instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QCmPnOKVbopd"
   },
   "outputs": [],
   "source": [
    "def IsHorizontal(img):\n",
    "    projected = []\n",
    "    rows, cols = img.shape\n",
    "    for i in range(rows):\n",
    "        proj_sum = 0\n",
    "        for j in range(cols):\n",
    "            if img[i][j] == 0:\n",
    "                proj_sum += 1\n",
    "        projected.append([1]*proj_sum + [0]*(cols-proj_sum))\n",
    "        if(proj_sum >= 0.9*cols):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vyFBp6KT1WBM"
   },
   "outputs": [],
   "source": [
    "label_map = {0:{0: 'N0'}, 1:{0:'b4',1:'a4'}, 2:{0:'g4',1:'f4'}, 3:{0:'e4',1:'d4'}, 4:{0:'c4',1:'b3'},\n",
    "             5:{0:'a3',1:'g3'}, 6:{0:'f3',1:'e3'}, 7:{0:'d3',1:'c3'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "W0y22s6tP0D9"
   },
   "outputs": [],
   "source": [
    "# with zipfile.ZipFile('Notes.zip', 'r') as zip_ref:\n",
    "#       zip_ref.extractall('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "x4Ui5nGQXLPs"
   },
   "outputs": [],
   "source": [
    "row_percentage = 0.3\n",
    "\n",
    "def calculate_thickness_spacing(rle, most_common):\n",
    "    bw_patterns = [most_common_bw_pattern(col, most_common) for col in rle]\n",
    "    bw_patterns = [x for x in bw_patterns if x]  # Filter empty patterns\n",
    "\n",
    "    flattened = []\n",
    "    for col in bw_patterns:\n",
    "        flattened += col\n",
    "\n",
    "    pair, count = Counter(flattened).most_common()[0]\n",
    "\n",
    "    line_thickness = min(pair)\n",
    "    line_spacing = max(pair)\n",
    "\n",
    "    return line_thickness, line_spacing\n",
    "\n",
    "\n",
    "def whitene(rle, vals, max_height):\n",
    "    rlv = []\n",
    "    for length, value in zip(rle, vals):\n",
    "        if value == 0 and length < 1.1*max_height:\n",
    "            value = 1\n",
    "        rlv.append((length, value))\n",
    "\n",
    "    n_rle, n_vals = [], []\n",
    "    count = 0\n",
    "    for length, value in rlv:\n",
    "        if value == 1:\n",
    "            count = count + length\n",
    "        else:\n",
    "            if count > 0:\n",
    "                n_rle.append(count)\n",
    "                n_vals.append(1)\n",
    "\n",
    "            count = 0\n",
    "            n_rle.append(length)\n",
    "            n_vals.append(0)\n",
    "    if count > 0:\n",
    "        n_rle.append(count)\n",
    "        n_vals.append(1)\n",
    "\n",
    "    return n_rle, n_vals\n",
    "\n",
    "\n",
    "def remove_staff_lines(rle, vals, thickness, shape):\n",
    "    n_rle, n_vals = [], []\n",
    "    for i in range(len(rle)):\n",
    "        rl, val = whitene(rle[i], vals[i], thickness)\n",
    "        n_rle.append(rl)\n",
    "        n_vals.append(val)\n",
    "\n",
    "    return hv_decode(n_rle, n_vals, shape)\n",
    "\n",
    "\n",
    "def remove_staff_lines_2(thickness, img_with_staff):\n",
    "    img = img_with_staff.copy()\n",
    "    projected = []\n",
    "    rows, cols = img.shape\n",
    "    for i in range(rows):\n",
    "        proj_sum = 0\n",
    "        for j in range(cols):\n",
    "            proj_sum += img[i][j] == 1\n",
    "        projected.append([1]*proj_sum + [0]*(cols-proj_sum))\n",
    "        if(proj_sum <= row_percentage*cols):\n",
    "            img[i, :] = 1\n",
    "    closed = binary_opening(img, np.ones((3*thickness, 1)))\n",
    "    return closed\n",
    "\n",
    "\n",
    "def get_rows(start, most_common, thickness, spacing):\n",
    "    # start = start-most_common\n",
    "    rows = []\n",
    "    num = 6\n",
    "    if start - most_common >= 0:\n",
    "        start -= most_common\n",
    "        num = 7\n",
    "    for k in range(num):\n",
    "        row = []\n",
    "        for i in range(thickness):\n",
    "            row.append(start)\n",
    "            start += 1\n",
    "        start += (spacing)\n",
    "        rows.append(row)\n",
    "    if len(rows) == 6:\n",
    "        rows = [0] + rows\n",
    "    return rows\n",
    "\n",
    "\n",
    "def horizontal_projection(img):\n",
    "    projected = []\n",
    "    rows, cols = img.shape\n",
    "    for i in range(rows):\n",
    "        proj_sum = 0\n",
    "        for j in range(cols):\n",
    "            proj_sum += img[i][j] == 1\n",
    "        projected.append([1]*proj_sum + [0]*(cols-proj_sum))\n",
    "        if(proj_sum <= 0.1*cols):\n",
    "            return i\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_staff_row_position(img):\n",
    "    found = 0\n",
    "    row_position = -1\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            if(img[i][j] == 0):\n",
    "                row_position = i\n",
    "                found = 1\n",
    "                break\n",
    "        if found == 1:\n",
    "            break\n",
    "    return row_position\n",
    "\n",
    "\n",
    "def coordinator(bin_img, horizontal):\n",
    "    rle, vals = hv_rle(bin_img)\n",
    "    most_common = get_most_common(rle)\n",
    "    thickness, spacing = calculate_thickness_spacing(rle, most_common)\n",
    "    start = 0\n",
    "    if horizontal:\n",
    "        no_staff_img = remove_staff_lines_2(thickness, bin_img)\n",
    "        staff_lines = otsu(bin_img - no_staff_img)\n",
    "        start = horizontal_projection(bin_img)\n",
    "    else:\n",
    "        no_staff_img = remove_staff_lines(rle, vals, thickness, bin_img.shape)\n",
    "        no_staff_img = binary_closing(\n",
    "            no_staff_img, np.ones((thickness+2, thickness+2)))\n",
    "        no_staff_img = median(no_staff_img)\n",
    "        no_staff_img = binary_opening(\n",
    "            no_staff_img, np.ones((thickness+2, thickness+2)))\n",
    "        staff_lines = otsu(bin_img - no_staff_img)\n",
    "        staff_lines = binary_erosion(\n",
    "            staff_lines, np.ones((thickness+2, thickness+2)))\n",
    "        staff_lines = median(staff_lines, selem=square(21))\n",
    "        start = get_staff_row_position(staff_lines)\n",
    "    staff_row_positions = get_rows(\n",
    "        start, most_common, thickness, spacing)\n",
    "    staff_row_positions = [np.average(x) for x in staff_row_positions]\n",
    "    return spacing, staff_row_positions, no_staff_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HhvtuKc7VxvN"
   },
   "outputs": [],
   "source": [
    "def rle_encode(arr):\n",
    "    if len(arr) == 0:\n",
    "        return [], [], []\n",
    "\n",
    "    x = np.copy(arr)\n",
    "    first_dismatch = np.array(x[1:] != x[:-1])\n",
    "    distmatch_positions = np.append(np.where(first_dismatch), len(x)-1)\n",
    "    rle = np.diff(np.append(-1, distmatch_positions))\n",
    "    values = [x[i] for i in np.cumsum(np.append(0, rle))[:-1]]\n",
    "    return rle, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oH55ZmY4VyYm"
   },
   "outputs": [],
   "source": [
    "def hv_rle(img, axis=1):\n",
    "    '''\n",
    "    img: binary image\n",
    "    axis: 0 for rows, 1 for cols\n",
    "    '''\n",
    "    rle, values = [], []\n",
    "\n",
    "    if axis == 1:\n",
    "        for i in range(img.shape[1]):\n",
    "            col_rle, col_values = rle_encode(img[:, i])\n",
    "            rle.append(col_rle)\n",
    "            values.append(col_values)\n",
    "    else:\n",
    "        for i in range(img.shape[0]):\n",
    "            row_rle, row_values = rle_encode(img[i])\n",
    "            rle.append(row_rle)\n",
    "            values.append(row_values)\n",
    "\n",
    "    return rle, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "g3k65KIbV1Kv"
   },
   "outputs": [],
   "source": [
    "def rle_decode(starts, lengths, values):\n",
    "    starts, lengths, values = map(np.asarray, (starts, lengths, values))\n",
    "    ends = starts + lengths\n",
    "    n = ends[-1]\n",
    "\n",
    "    x = np.full(n, np.nan)\n",
    "    for lo, hi, val in zip(starts, ends, values):\n",
    "        x[lo:hi] = val\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tzuzmHirV4Qh"
   },
   "outputs": [],
   "source": [
    "def hv_decode(rle, values, output_shape, axis=1):\n",
    "    starts = [[int(np.sum(arr[:i])) for i in range(len(arr))] for arr in rle]\n",
    "\n",
    "    decoded = np.zeros(output_shape, dtype=np.int32)\n",
    "    if axis == 1:\n",
    "        for i in range(decoded.shape[1]):\n",
    "            decoded[:, i] = rle_decode(starts[i], rle[i], values[i])\n",
    "    else:\n",
    "        for i in range(decoded.shape[0]):\n",
    "            decoded[i] = rle_decode(starts[i], rle[i], values[i])\n",
    "\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "shFT2gucV_kP"
   },
   "outputs": [],
   "source": [
    "def calculate_pair_sum(arr):\n",
    "    if len(arr) == 1:\n",
    "        return list(arr)\n",
    "    else:\n",
    "        res = [arr[i] + arr[i + 1] for i in range(0, len(arr) - 1, 2)]\n",
    "        if len(arr) % 2 == 1:\n",
    "            res.append(arr[-2] + arr[-1])\n",
    "        return res\n",
    "\n",
    "\n",
    "def get_most_common(rle):\n",
    "    pair_sum = [calculate_pair_sum(col) for col in rle]\n",
    "\n",
    "    flattened = []\n",
    "    for col in pair_sum:\n",
    "        flattened += col\n",
    "\n",
    "    most_common = np.argmax(np.bincount(flattened))\n",
    "    return most_common\n",
    "\n",
    "\n",
    "def most_common_bw_pattern(arr, most_common):\n",
    "    if len(arr) == 1:\n",
    "        # print(\"Empty\")\n",
    "        return []\n",
    "    else:\n",
    "        res = [(arr[i], arr[i + 1]) for i in range(0, len(arr) - 1, 2)\n",
    "               if arr[i] + arr[i + 1] == most_common]\n",
    "\n",
    "        if len(arr) % 2 == 1 and arr[-2] + arr[-1] == most_common:\n",
    "            res.append((arr[-2], arr[-1]))\n",
    "        # print(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "sDqpfGIQRXxs"
   },
   "outputs": [],
   "source": [
    "def gray_img(img):\n",
    "    '''\n",
    "    img: rgb image\n",
    "    return: gray image, pixel values 0:255\n",
    "    '''\n",
    "    if img.shape[2] == 4:  # перевіряємо, чи є у зображення альфа-канал\n",
    "        img = img[:, :, :3]  # видаляємо альфа-канал\n",
    "    gray = rgb2gray(img)\n",
    "    gray = (gray * 255).astype(np.uint8)  # перетворюємо зображення у формат 8-бітового сірого\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SKp9KcbZVT4C"
   },
   "outputs": [],
   "source": [
    "class Box(object):\n",
    "    def __init__(self, x, y, w, h):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "        self.center = x + w/2, self.y+self.h/2\n",
    "        self.area = w*h\n",
    "\n",
    "    def overlap(self, other):\n",
    "        x = max(0, min(self.x+self.w, other.x+other.w) - max(other.x, self.x))\n",
    "        y = max(0, min(self.y+self.h, other.y+other.h) - max(other.y, self.y))\n",
    "        area = x*y\n",
    "        return area/self.area\n",
    "\n",
    "    def distance(self, other):\n",
    "        return math.sqrt((self.center[0]-other.center[0])**2+(self.center[1]-other.center[1])**2)\n",
    "\n",
    "    def merge(self, other):\n",
    "        x = min(self.x, other.x)\n",
    "        y = max(self.y, other.y)\n",
    "        w = max(self.x+self.w, other.x+other.w) - x\n",
    "        h = max(self.y+self.h, other.y+other.h) - y\n",
    "        return Box(x, y, w, h)\n",
    "\n",
    "    def draw(self, img, color, thickness):\n",
    "        pos = ((int)(self.x), (int)(self.y))\n",
    "        size = ((int)(self.x + self.w), (int)(self.y + self.h))\n",
    "        cv2.rectangle(img, pos, size, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3FNtA6wl1_ZK"
   },
   "outputs": [],
   "source": [
    "def read_all_images(num_of_images):\n",
    "    all_images_list = []\n",
    "    for i in range(num_of_images):\n",
    "        path = f'C:/Users/User/Desktop/Diplomna/notes/music sheet ({i+1}).png'\n",
    "        img = gray_img(io.imread(path))\n",
    "        all_images_list.append(get_thresholded(img, threshold_otsu(img)))\n",
    "    return all_images_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5kWeKxEbVL6H"
   },
   "outputs": [],
   "source": [
    "def predict(img):\n",
    "    if not os.path.exists('nn_trained_model_hog.sav'):\n",
    "        print('Please wait while training the NN-HOG model....')\n",
    "        train('NN', 'hog', 'nn_trained_model_hog')\n",
    "\n",
    "    model = pickle.load(open('nn_trained_model_hog.sav', 'rb'))\n",
    "    features = extract_features(img, 'hog')\n",
    "    labels = model.predict([features])\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LwhA78TBU1Vv"
   },
   "outputs": [],
   "source": [
    "class Segmenter(object):\n",
    "    def __init__(self, bin_img):\n",
    "        self.bin_img = bin_img\n",
    "        self.rle, self.vals = hv_rle(self.bin_img)\n",
    "        self.most_common = get_most_common(self.rle)\n",
    "        self.thickness, self.spacing = calculate_thickness_spacing(\n",
    "            self.rle, self.most_common)\n",
    "        self.thick_space = self.thickness + self.spacing\n",
    "        self.no_staff_img = remove_staff_lines(\n",
    "            self.rle, self.vals, self.thickness, self.bin_img.shape)\n",
    "\n",
    "        self.segment()\n",
    "\n",
    "    def open_region(self, region):\n",
    "        thickness = np.copy(self.thickness)\n",
    "        # if thickness % 2 == 0:\n",
    "        #     thickness += 1\n",
    "        return opening(region, np.ones((thickness, thickness)))\n",
    "\n",
    "    def segment(self):\n",
    "        self.line_indices = get_line_indices(histogram(self.bin_img, 0.8))\n",
    "        if len(self.line_indices) < 10:\n",
    "            self.regions_without_staff = [\n",
    "                np.copy(self.open_region(self.no_staff_img))]\n",
    "            self.regions_with_staff = [np.copy(self.bin_img)]\n",
    "            return\n",
    "\n",
    "        generated_lines_img = np.copy(self.no_staff_img)\n",
    "        lines = []\n",
    "        for index in self.line_indices:\n",
    "            line = ((0, index), (self.bin_img.shape[1]-1, index))\n",
    "            lines.append(line)\n",
    "\n",
    "        end_of_staff = []\n",
    "        for index, line in enumerate(lines):\n",
    "            if index > 0 and (line[0][1] - end_of_staff[-1][1] < 4*self.spacing):\n",
    "                pass\n",
    "            else:\n",
    "                p1, p2 = line\n",
    "                x0, y0 = p1\n",
    "                x1, y1 = p2\n",
    "                end_of_staff.append((x0, y0, x1, y1))\n",
    "\n",
    "        box_centers = []\n",
    "        spacing_between_staff_blocks = []\n",
    "        for i in range(len(end_of_staff)-1):\n",
    "            spacing_between_staff_blocks.append(\n",
    "                end_of_staff[i+1][1] - end_of_staff[i][1])\n",
    "            if i % 2 == 0:\n",
    "                offset = (end_of_staff[i+1][1] - end_of_staff[i][1])//2\n",
    "                center = end_of_staff[i][1] + offset\n",
    "                box_centers.append((center, offset))\n",
    "\n",
    "        max_staff_dist = np.max(spacing_between_staff_blocks)\n",
    "        max_margin = max_staff_dist // 2\n",
    "        margin = max_staff_dist // 10\n",
    "\n",
    "        end_points = []\n",
    "        regions_without_staff = []\n",
    "        regions_with_staff = []\n",
    "        for index, (center, offset) in enumerate(box_centers):\n",
    "            y0 = int(center) - max_margin - offset + margin\n",
    "            y1 = int(center) + max_margin + offset - margin\n",
    "            end_points.append((y0, y1))\n",
    "\n",
    "            region = self.bin_img[y0:y1, 0:self.bin_img.shape[1]]\n",
    "            regions_with_staff.append(region)\n",
    "            staff_block = self.no_staff_img[y0:y1,\n",
    "                                            0:self.no_staff_img.shape[1]]\n",
    "\n",
    "            regions_without_staff.append(self.open_region(staff_block))\n",
    "\n",
    "        self.regions_without_staff = regions_without_staff\n",
    "        self.regions_with_staff = regions_with_staff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "JJnZU0KW2dKL"
   },
   "outputs": [],
   "source": [
    "def segmenting(img):\n",
    "    segmenter = Segmenter(get_thresholded(img, threshold_otsu(img))) #binary image\n",
    "    imgs_with_staff = segmenter.regions_with_staff\n",
    "    imgs_spacing, imgs_rows, coord_imgs  = [], [], []\n",
    "    for i, img in enumerate(imgs_with_staff):\n",
    "        spacing, rows, no_staff_img = coordinator(img,IsHorizontal(img))\n",
    "        imgs_rows.append(rows)\n",
    "        imgs_spacing.append(spacing)\n",
    "        coord_imgs.append(no_staff_img)\n",
    "    return segmenter, imgs_spacing, imgs_rows, coord_imgs, imgs_with_staff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "wkeN2daJ2gPI"
   },
   "outputs": [],
   "source": [
    "def estim(c, idx, imgs_spacing, imgs_rows):\n",
    "    spacing = imgs_spacing[idx]\n",
    "    rows = imgs_rows[idx]\n",
    "    margin = 1+(spacing/4)\n",
    "    for index,line in enumerate (rows):\n",
    "        if c >= line - margin and c <= line + margin:\n",
    "            return index+1, 0\n",
    "        elif c >= line + margin and c <= line + 3*margin:\n",
    "            return index+1, 1\n",
    "    return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "GLCqSUNk2iuz"
   },
   "outputs": [],
   "source": [
    "def filter_beams(prims, prim_with_staff, bounds):\n",
    "    n_bounds, n_prims, n_prim_with_staff = [], [], []\n",
    "    for i, prim in enumerate(prims):\n",
    "        if prim.shape[1] >= 2*prim.shape[0]:\n",
    "            continue\n",
    "        else:\n",
    "            n_bounds.append(bounds[i])\n",
    "            n_prims.append(prims[i])\n",
    "            n_prim_with_staff.append(prim_with_staff[i])\n",
    "    return n_prims, n_prim_with_staff, n_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "vxYzTNVxRRaX"
   },
   "outputs": [],
   "source": [
    "def show_images(images, titles=None):\n",
    "    n_ims = len(images)\n",
    "    if titles is None:\n",
    "        titles = ['(%d)' % i for i in range(1, n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image, title in zip(images, titles):\n",
    "        a = fig.add_subplot(1, n_ims, n)\n",
    "        if image.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        plt.axis('off')\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "_HKIsOYORUeG"
   },
   "outputs": [],
   "source": [
    "def showHist(img):\n",
    "    plt.figure()\n",
    "    imgHist = histogram(img, nbins=256)\n",
    "\n",
    "    bar(imgHist[1].astype(np.uint8), imgHist[0], width=0.8, align='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "wLqz6Wy_RdTF"
   },
   "outputs": [],
   "source": [
    "def otsu(img):\n",
    "    '''\n",
    "    Otsu with gaussian\n",
    "    img: gray image\n",
    "    return: binary image, pixel values 0:1\n",
    "    '''\n",
    "    blur = gaussian(img)\n",
    "    otsu_bin = 255*(blur > threshold_otsu(blur))\n",
    "    return (otsu_bin/255).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "51QQv7oRbC1A"
   },
   "outputs": [],
   "source": [
    "target_img_size = (100, 100)\n",
    "sample_count = 50\n",
    "\n",
    "\n",
    "def extract_raw_pixels(img):\n",
    "    resized = cv2.resize(img, target_img_size)\n",
    "    return resized.flatten()\n",
    "\n",
    "\n",
    "def extract_hsv_histogram(img):\n",
    "    resized = cv2.resize(img, target_img_size)\n",
    "    hsv = cv2.cvtColor(resized, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, [8, 8, 8],\n",
    "                        [0, 180, 0, 256, 0, 256])\n",
    "    if imutils.is_cv2():\n",
    "        hist = cv2.normalize(hist)\n",
    "    else:\n",
    "        cv2.normalize(hist, hist)\n",
    "    return hist.flatten()\n",
    "\n",
    "\n",
    "def extract_hog_features(img):\n",
    "    img = cv2.resize(img, target_img_size)\n",
    "    win_size = (100, 100)\n",
    "    cell_size = (4, 4)\n",
    "    block_size_in_cells = (2, 2)\n",
    "\n",
    "    block_size = (block_size_in_cells[1] * cell_size[1],\n",
    "                  block_size_in_cells[0] * cell_size[0])\n",
    "    block_stride = (cell_size[1], cell_size[0])\n",
    "    nbins = 9  # Number of orientation bins\n",
    "    hog = cv2.HOGDescriptor(win_size, block_size,\n",
    "                            block_stride, cell_size, nbins)\n",
    "    h = hog.compute(img)\n",
    "    h = h.flatten()\n",
    "    return h.flatten()\n",
    "\n",
    "\n",
    "def extract_features(img, feature_set='raw'):\n",
    "    if feature_set == 'hog':\n",
    "        return extract_hog_features(img)\n",
    "    elif feature_set == 'raw':\n",
    "        return extract_raw_pixels(img)\n",
    "    else:\n",
    "        return extract_hsv_histogram(img)\n",
    "\n",
    "\n",
    "def load_dataset(feature_set='raw', dir_names=[]):\n",
    "    features = []\n",
    "    labels = []\n",
    "    count = 0\n",
    "    for dir_name in dir_names:\n",
    "        print(dir_name)\n",
    "        imgs = glob(f'{dataset_path}/{dir_name}/*.png')\n",
    "        count += len(imgs)\n",
    "        subset = random.sample([i for i in range(len(imgs))], min(len(imgs), sample_count))\n",
    "        for i in subset:\n",
    "            img = cv2.imread(imgs[i])\n",
    "            labels.append(dir_name)\n",
    "            features.append(extract_features(img, feature_set))\n",
    "    print(f'Total: {len(dir_names)} directories, and {count} images')\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def load_classifiers():\n",
    "    random_seed = 42\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    classifiers = {\n",
    "        'SVM': svm.LinearSVC(random_state=random_seed),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=7),\n",
    "        'NN': MLPClassifier(activation='relu', hidden_layer_sizes=(200,),\n",
    "                            max_iter=10000, alpha=1e-4,\n",
    "                            solver='adam', verbose=20,\n",
    "                            tol=1e-8, random_state=1,\n",
    "                            learning_rate_init=.0001,\n",
    "                            learning_rate='adaptive')\n",
    "    }\n",
    "    return classifiers, random_seed\n",
    "\n",
    "\n",
    "def run_experiment(classifier='SVM', feature_set='hog', dir_names=[]):\n",
    "    print('Loading dataset. This will take time ...')\n",
    "    features, labels = load_dataset(feature_set, dir_names)\n",
    "    print('Finished loading dataset.')\n",
    "\n",
    "    classifiers, random_seed = load_classifiers()\n",
    "\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "        features, labels, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "    model = classifiers[classifier]\n",
    "    print('############## Training', classifier, \"##############\")\n",
    "    model.fit(train_features, train_labels)\n",
    "    accuracy = model.score(test_features, test_labels)\n",
    "    print(classifier, 'accuracy:', accuracy*100, '%')\n",
    "\n",
    "    return model, accuracy\n",
    "\n",
    "\n",
    "def train(model_name, feature_name, saved_model_name):\n",
    "    dir_names = [path.split('/')[2] for path in glob(f'{dataset_path}/*')]\n",
    "\n",
    "    model, accuracy = run_experiment(model_name, feature_name, dir_names)\n",
    "\n",
    "    filename = f'trained_models/{saved_model_name}.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "sT4SFyxGRd5N"
   },
   "outputs": [],
   "source": [
    "def get_gray(img):\n",
    "    gray = rgb2gray(np.copy(img))\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "bQs1IS3BRlgP"
   },
   "outputs": [],
   "source": [
    "def get_thresholded(img, thresh):\n",
    "    return 1*(img > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "8GGepMEURo3U"
   },
   "outputs": [],
   "source": [
    "def histogram(img, thresh):\n",
    "    hist = (np.ones(img.shape) - img).sum(dtype=np.int32, axis=1)\n",
    "    _max = np.amax(hist)\n",
    "    hist[hist[:] < _max * thresh] = 0\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "szCNsDirRuPy"
   },
   "outputs": [],
   "source": [
    "def get_line_indices(hist):\n",
    "    indices = []\n",
    "    prev = 0\n",
    "    for index, val in enumerate(hist):\n",
    "        if val > 0 and prev <= 0:\n",
    "            indices.append(index)\n",
    "        prev = val\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "7PoJAjQ9RuRE"
   },
   "outputs": [],
   "source": [
    "def get_region_lines_indices(self, region):\n",
    "    indices = get_line_indices(histogram(region, 0.8))\n",
    "    lines = []\n",
    "    for line_index in indices:\n",
    "        line = []\n",
    "        for k in range(self.thickness):\n",
    "            line.append(line_index+k)\n",
    "        lines.append(line)\n",
    "    self.rows.append([np.average(x) for x in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "rNLVwH2LRIU_"
   },
   "outputs": [],
   "source": [
    "def get_connected_components(img_without_staff, img_with_staff):\n",
    "    components = []\n",
    "    boundary = []\n",
    "    # thresh = threshold_otsu(img_without_staff)\n",
    "    # bw = closing(img_without_staff <= thresh, square(3))\n",
    "    bw = 1-img_without_staff\n",
    "    label_img = label(bw)\n",
    "    img_label_overlay = label2rgb(\n",
    "        label_img, image=img_without_staff, bg_label=0)\n",
    "    for region in regionprops(label_img):\n",
    "        if region.area >= 100:\n",
    "            boundary.append(region.bbox)\n",
    "\n",
    "    boundary = sorted(boundary, key=lambda b: b[1])\n",
    "\n",
    "    comp_with_staff = []\n",
    "    for bbox in boundary:\n",
    "        minr, minc, maxr, maxc = bbox\n",
    "        components.append(img_without_staff[minr:maxr, minc:maxc])\n",
    "        comp_with_staff.append(img_with_staff[minr:maxr, minc:maxc])\n",
    "    return components, comp_with_staff, boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "NEoxzOvw2k_1"
   },
   "outputs": [],
   "source": [
    "def get_labeled_data(img):\n",
    "    labels_list, images_list = [], []\n",
    "    segmenter, imgs_spacing, imgs_rows, coord_imgs, imgs_with_staff = segmenting(img)\n",
    "    black_names = ['4', '8', '8_b_n', '8_b_r', '16', '16_b_n', '16_b_r', '32', '32_b_n', '32_b_r', 'a_4',\n",
    "                   'a_8', 'a_16', 'a_32', 'chord']\n",
    "    disk_size = segmenter.most_common / 4\n",
    "    for i, img in enumerate(coord_imgs):\n",
    "        primitives, prim_with_staff, boundary = get_connected_components(img, imgs_with_staff[i])\n",
    "        for j, prim in enumerate(primitives):\n",
    "            prim = binary_opening(prim, square(segmenter.most_common-imgs_spacing[i]))\n",
    "            label = predict((255*(1 - prim)).astype(np.uint8))[0]\n",
    "            if label in black_names:\n",
    "                test_img = binary_dilation(np.copy(prim_with_staff[j]), disk(disk_size))\n",
    "                comps, comp_w_staff, bounds = get_connected_components(test_img, prim_with_staff[j])\n",
    "                comps, comp_w_staff, bounds = filter_beams(comps, comp_w_staff, bounds)\n",
    "                bounds = [np.array(bound)+disk_size-2 for bound in bounds]\n",
    "                if len(bounds) <= 1 or label in ['8_b_n', '8_b_r', '16_b_n', '16_b_r', '32_b_n', '32_b_r']:\n",
    "                    for bbox in bounds:\n",
    "                        line_idx, p = estim(int(bbox[2]+boundary[j][0]), i, imgs_spacing, imgs_rows)\n",
    "                        labels_list.append(label_map[line_idx][p])\n",
    "                        images_list.append(prim_with_staff[j])\n",
    "            elif label in ['2', 'a_2']:\n",
    "                head_img = binary_closing(1-binary_fill_holes(1-prim), disk(disk_size))\n",
    "                comps, comp_w_staff, bounds = get_connected_components(head_img, prim_with_staff[j])\n",
    "                for bbox in bounds:\n",
    "                    line_idx, p = estim(int(bbox[2]+boundary[j][0]), i, imgs_spacing, imgs_rows)\n",
    "                    labels_list.append(label_map[line_idx][p])\n",
    "                    images_list.append(prim_with_staff[j])\n",
    "            elif label in ['1', 'a_1']:\n",
    "                line_idx, p = estim(int(boundary[j][2]), i, imgs_spacing, imgs_rows)\n",
    "                labels_list.append(label_map[line_idx][p])\n",
    "                images_list.append(prim_with_staff[j])\n",
    "    return labels_list, images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "gAzDDr9F2nuz",
    "outputId": "9336871e-85c5-43fc-ca78-c2960d8b0ea5"
   },
   "outputs": [],
   "source": [
    "# all_images = read_all_images(2500)\n",
    "# all_images_labels, all_images_arr, all_images_ids =[], [], []\n",
    "# for i, image in tqdm(enumerate(all_images)):\n",
    "#     labels_list, images_list = get_labeled_data(image)\n",
    "#     all_images_labels += labels_list\n",
    "#     all_images_arr += images_list\n",
    "#     all_images_ids += [i] * len(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "id": "v7Q4VTRt_KBl",
    "outputId": "7b165640-fb9e-45e6-b3bb-5ec6f375f3e2"
   },
   "outputs": [],
   "source": [
    "#view some labels\n",
    "# print(all_images_labels[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "nMddoFq6_KCr"
   },
   "outputs": [],
   "source": [
    "#view some images\n",
    "# show_images(all_images_arr[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "KbFHCT9O_QIm"
   },
   "outputs": [],
   "source": [
    "#check that all lengths match\n",
    "# len(all_images_labels) == len(all_images_arr) == len(all_images_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "MyOgP15z_R-V",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Store the data in a dataframe\n",
    "# df = pd.DataFrame(data= {'ID':all_images_ids, 'img': all_images_arr, 'label': all_images_labels})\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "RbgYkzlx_XG0"
   },
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "kG7ciXUQi3Cr"
   },
   "outputs": [],
   "source": [
    "# df.to_hdf('all_images_data.h5', key='data', mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "ILv4c7EAl1Kk"
   },
   "outputs": [],
   "source": [
    "df = pd.read_hdf('all_images_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "qCSZgv8j_Y5u"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>c4</th>\n",
       "      <th>g4</th>\n",
       "      <th>a4</th>\n",
       "      <th>f4</th>\n",
       "      <th>e4</th>\n",
       "      <th>d4</th>\n",
       "      <th>a3</th>\n",
       "      <th>N0</th>\n",
       "      <th>b4</th>\n",
       "      <th>b3</th>\n",
       "      <th>e3</th>\n",
       "      <th>g3</th>\n",
       "      <th>f3</th>\n",
       "      <th>d3</th>\n",
       "      <th>c3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>c4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>c4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,...</td>\n",
       "      <td>g4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,...</td>\n",
       "      <td>g4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>a4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                                img label  c4  g4  a4  \\\n",
       "0   0  [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,...    c4   0   0   0   \n",
       "1   0  [[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,...    c4   0   0   0   \n",
       "2   0  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,...    g4   0   0   0   \n",
       "3   0  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,...    g4   0   0   0   \n",
       "4   0  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...    a4   0   0   0   \n",
       "\n",
       "   f4  e4  d4  a3  N0  b4  b3  e3  g3  f3  d3  c3  \n",
       "0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0   0   0   0   0   0   0  \n",
       "2   0   0   0   0   0   0   0   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0   0   0   0   0   0   0  \n",
       "4   0   0   0   0   0   0   0   0   0   0   0   0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a column for each unique label\n",
    "unique_labels = df.label.unique()\n",
    "for label in unique_labels:\n",
    "    df[label] = 0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "U0G51QHZ_aTQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>c4</th>\n",
       "      <th>g4</th>\n",
       "      <th>a4</th>\n",
       "      <th>f4</th>\n",
       "      <th>e4</th>\n",
       "      <th>d4</th>\n",
       "      <th>a3</th>\n",
       "      <th>N0</th>\n",
       "      <th>b4</th>\n",
       "      <th>b3</th>\n",
       "      <th>e3</th>\n",
       "      <th>g3</th>\n",
       "      <th>f3</th>\n",
       "      <th>d3</th>\n",
       "      <th>c3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>c4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>c4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,...</td>\n",
       "      <td>g4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,...</td>\n",
       "      <td>g4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>a4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                                img label  c4  g4  a4  \\\n",
       "0   0  [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,...    c4   1   0   0   \n",
       "1   0  [[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,...    c4   1   0   0   \n",
       "2   0  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,...    g4   0   1   0   \n",
       "3   0  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,...    g4   0   1   0   \n",
       "4   0  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...    a4   0   0   1   \n",
       "\n",
       "   f4  e4  d4  a3  N0  b4  b3  e3  g3  f3  d3  c3  \n",
       "0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0   0   0   0   0   0   0  \n",
       "2   0   0   0   0   0   0   0   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0   0   0   0   0   0   0  \n",
       "4   0   0   0   0   0   0   0   0   0   0   0   0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filling each column with the corresponding label\n",
    "for i, label in enumerate(df.label):\n",
    "    df[label][i] = 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "1No-t6_x_cA9"
   },
   "outputs": [],
   "source": [
    "def unify_shape(df):\n",
    "    rows, cols = [], []\n",
    "    for image in df.img:\n",
    "        rows.append(image.shape[0])\n",
    "        cols.append(image.shape[1])\n",
    "\n",
    "    rows = max(rows)\n",
    "    cols = max(cols)\n",
    "    for i in range(len(df)):\n",
    "        add_rows = np.ones((rows - df['img'][i].shape[0], df['img'][i].shape[1]), dtype = int)\n",
    "        df['img'][i] = np.vstack((df['img'][i], add_rows))\n",
    "\n",
    "        add_cols = np.ones((rows, cols - df['img'][i].shape[1]), dtype = int)\n",
    "        df['img'][i] = np.hstack((df['img'][i], add_cols))\n",
    "    return df, rows, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "e0isDSJb_hiz"
   },
   "outputs": [],
   "source": [
    "df, rows, cols = unify_shape(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "nwOfmscZ_jGE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169, 280)\n",
      "(169, 280)\n",
      "(169, 280)\n",
      "(169, 280)\n",
      "(169, 280)\n"
     ]
    }
   ],
   "source": [
    "#checking shapes\n",
    "for x in df.img[:5]:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "HHIJOvRD_lQO"
   },
   "outputs": [],
   "source": [
    "\n",
    "#split the data based on the number of images -> each music sheet\n",
    "train_data = df[df.ID >= int(df.ID.nunique() * 0.2)]\n",
    "test_data = df[df.ID < int(df.ID.nunique() * 0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "pKVXLy-r_m4P"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = train_data['img'], np.asarray(train_data.drop(columns=['ID','img','label']))\n",
    "X_test, y_test = test_data['img'], np.asarray(test_data.drop(columns=['ID','img','label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "ahFs4TpQ_oab"
   },
   "outputs": [],
   "source": [
    "def reshape_x(X):\n",
    "    return np.asarray([x.reshape((rows, cols, 1)) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "DgvhIPQM_obk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19552, 169, 280, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = reshape_x(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "i2CtSVqW_uhH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19552, 15)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "Q0LdHGVq_xLP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4345, 169, 280, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = reshape_x(X_test)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "65U1hJ82_ylN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4345, 15)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "-r-fIN50_zop"
   },
   "outputs": [],
   "source": [
    "# NN = Sequential()\n",
    "# NN.add(InputLayer(input_shape=X_train.shape[1:]))\n",
    "\n",
    "# NN.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "# NN.add(MaxPooling2D())\n",
    "# NN.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "# NN.add(MaxPooling2D())\n",
    "# NN.add(Conv2D(filters=256, kernel_size=3, activation='relu'))\n",
    "# NN.add(MaxPooling2D())\n",
    "# NN.add(Conv2D(filters=512, kernel_size=3, activation='relu'))\n",
    "# NN.add(MaxPooling2D())\n",
    "# NN.add(Conv2D(filters=1024, kernel_size=3, activation='relu'))\n",
    "# NN.add(MaxPooling2D())\n",
    "\n",
    "# NN.add(GlobalAveragePooling2D())\n",
    "\n",
    "# # NN.add(Dropout(0.5))\n",
    "\n",
    "# NN.add(Dense(2048, activation='relu'))\n",
    "# NN.add(Dense(df.label.nunique(), activation='softmax'))\n",
    "\n",
    "# NN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# NN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "_qk9LUhb_1dK"
   },
   "outputs": [],
   "source": [
    "# NN.fit(X_train, y_train, epochs=30, verbose=1, validation_split=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN.save(\"trained_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\.virtualenvs\\Diplomna\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\.virtualenvs\\Diplomna\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NN = load_model(\"trained_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "GoeQBCF5_3d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 103s 752ms/step\n",
      "['d4', 'd4', 'b3', 'b3', 'N0', 'N0', 'b3', 'b3', 'b3', 'b3', 'd4', 'd4', 'f4', 'f4', 'f4', 'd4', 'b3', 'b3', 'f4', 'b3', 'd4', 'd4', 'f4', 'f4', 'b3', 'b3', 'e4', 'b3', 'd4', 'e4', 'e4', 'a3', 'g4', 'N0', 'g4', 'g4', 'N0', 'g4', 'N0', 'e4', 'g4', 'f4', 'b3', 'f4', 'a3', 'N0', 'f4', 'N0', 'f4', 'g4']\n"
     ]
    }
   ],
   "source": [
    "#storing the predictions\n",
    "results = []\n",
    "pred = NN.predict(X_test)\n",
    "for p in pred:\n",
    "    results.append(unique_labels[np.argmax(p)])\n",
    "print(results[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "G-gN7C3V_4_v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\.virtualenvs\\Diplomna\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "The test accuracy is 71.32 %\n"
     ]
    }
   ],
   "source": [
    "print('The test accuracy is', round(NN.evaluate(X_test, y_test, verbose=0)[1] * 100, 2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "9Ygl0fH__6gq"
   },
   "outputs": [],
   "source": [
    "#storing the list of predicted notes for each sheet (image)\n",
    "IDs = list(test_data.ID)\n",
    "num_of_notes = IDs.count(0) #for the first image\n",
    "results_dict = {}\n",
    "results_dict[0] = results[:num_of_notes]\n",
    "for i in range(test_data.ID.nunique() - 1):\n",
    "    results_dict[i+1] = results[num_of_notes : num_of_notes + IDs.count(i+1)]\n",
    "    num_of_notes += IDs.count(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "EiLh43iW_79g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b4', 'b4', 'b4', 'b4', 'b4', 'a4', 'a4', 'a4', 'a4', 'a4', 'b4', 'b4', 'b4', 'b4']\n"
     ]
    }
   ],
   "source": [
    "print(results_dict[2]) #predi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'music_with_violin.mid'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def notes_to_music_with_instrument(notes_sequence, instrument_name):\n",
    "    # Створення нового музичного листа\n",
    "    music_stream = stream.Stream()\n",
    "\n",
    "    # Визначення інструменту\n",
    "    instr = instrument.fromString(instrument_name)\n",
    "    music_stream.insert(0, instr)\n",
    "\n",
    "    # Додавання нот до музичного листа\n",
    "    for note_name in notes_sequence:\n",
    "        if len(note_name) == 2:\n",
    "            new_note = note.Note(note_name)\n",
    "            music_stream.append(new_note)\n",
    "\n",
    "    # Задання темпу\n",
    "    music_stream.insert(0, tempo.MetronomeMark(number=120))\n",
    "\n",
    "    return music_stream\n",
    "\n",
    "# Конвертування послідовності нот у музику зі скрипкою як інструментом\n",
    "music_with_violin = notes_to_music_with_instrument(results_dict[2], 'Violin')\n",
    "\n",
    "# Збереження музики у форматі MIDI\n",
    "file_path = \"music_with_violin.mid\"\n",
    "music_with_violin.write('midi', fp=file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "NwigIvJB_7_I"
   },
   "outputs": [],
   "source": [
    "#getting the notes and frequencies from wikipedia\n",
    "page = requests.get('https://en.wikipedia.org/wiki/Piano_key_frequencies')\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "VpZKyxZKrjD-"
   },
   "outputs": [],
   "source": [
    "#initializing with a Quarter Note Rest, which has a 0 frequency\n",
    "note = ['N0']\n",
    "frequency = ['0']\n",
    "for i, row in enumerate(soup.find('table', class_=\"wikitable sortable\").find_all('tr')):\n",
    "    if i < 2: #skipping the headers\n",
    "        continue\n",
    "    note.append(row.find_all('td')[3].text.strip().lower()) #third element is the note\n",
    "    frequency.append(row.find_all('td')[4].text.strip()) #fourth element is the note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "h2ZUr4ihrn2A"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b8</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a♯8/b♭8</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a8</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g♯8/a♭8</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      note frequency\n",
       "0       N0         0\n",
       "1       b8        99\n",
       "2  a♯8/b♭8        98\n",
       "3       a8        97\n",
       "4  g♯8/a♭8        96"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Store the data in a dataframe\n",
    "frequency_df = pd.DataFrame(data= {'note':note, 'frequency': frequency})\n",
    "frequency_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "cuA00hDUrppN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N0', 'b4', 'g4', 'e4', 'c4', 'a3', 'f3', 'd3', 'a4', 'f4', 'd4', 'b3', 'g3', 'e3', 'c3']\n"
     ]
    }
   ],
   "source": [
    "#getting the list of labels\n",
    "original_labels_df = pd.DataFrame.from_dict(label_map, orient='index').reset_index(drop=True)\n",
    "original_labels_list = list(original_labels_df[0]) + list(original_labels_df[1][1:])\n",
    "print(original_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "MRpEiPhVrprB"
   },
   "outputs": [],
   "source": [
    "#collecting the index of the notes that are not in our labels list\n",
    "idx_to_drop = []\n",
    "for i, note in enumerate(frequency_df.note):\n",
    "    if note.split()[0] not in original_labels_list:\n",
    "        idx_to_drop.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "5ZG5fmGwrx8W"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b4</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a4  a440</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g4</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>e4</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d4</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c4 middle c</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b3</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a3</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>g3</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>f3</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>e3</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>d3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>c3</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           note frequency\n",
       "0            N0         0\n",
       "1            b4        51\n",
       "2      a4  a440        49\n",
       "3            g4        47\n",
       "4            f4        45\n",
       "5            e4        44\n",
       "6            d4        42\n",
       "7   c4 middle c        40\n",
       "8            b3        39\n",
       "9            a3        37\n",
       "10           g3        35\n",
       "11           f3        33\n",
       "12           e3        32\n",
       "13           d3        30\n",
       "14           c3        28"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping the notes that are not in our labels list\n",
    "frequency_df = frequency_df.drop(index=idx_to_drop).reset_index(drop=True)\n",
    "frequency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "Fxoxqmdprzka"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b4</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a4</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g4</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>e4</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d4</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b3</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a3</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>g3</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>f3</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>e3</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>d3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>c3</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   note frequency\n",
       "0    N0         0\n",
       "1    b4        51\n",
       "2    a4        49\n",
       "3    g4        47\n",
       "4    f4        45\n",
       "5    e4        44\n",
       "6    d4        42\n",
       "7    c4        40\n",
       "8    b3        39\n",
       "9    a3        37\n",
       "10   g3        35\n",
       "11   f3        33\n",
       "12   e3        32\n",
       "13   d3        30\n",
       "14   c3        28"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#manually clean two rows\n",
    "frequency_df.iloc[2].note = 'a4'\n",
    "frequency_df.iloc[7].note = 'c4'\n",
    "frequency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "ekftLSM5r4M5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that both lengths match\n",
    "len(original_labels_list) == len(frequency_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "jYQRK5Vvr9M8"
   },
   "outputs": [],
   "source": [
    "#from the official documentation of SciPy\n",
    "samplerate = 44100 #Frequecy in Hz\n",
    "amplitude = np.iinfo(np.int16).max\n",
    "t = np.linspace(0., 0.5, int(samplerate * 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "kq2Hymspr-2n"
   },
   "outputs": [],
   "source": [
    "#producing the music of the first sheet\n",
    "waves = []\n",
    "for note in results_dict[0]:\n",
    "    freq = float(frequency_df[frequency_df.note == note].frequency.values[0])\n",
    "    wave = amplitude * np.sin(2 * np.pi * freq * t)\n",
    "    waves.append(wave)\n",
    "song_data = np.concatenate(waves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "PFqJ4B8isBfc"
   },
   "outputs": [],
   "source": [
    "#outputs a wav audio file of the song\n",
    "write('song.wav', samplerate, song_data.astype(np.int16))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
